
I need to make some decisions regarding


TO DO:

x Set up git repo (DO THIS FIRST!)

x Add event queue (DO THIS SECOND!)
The audio generation shouldn't be done inside an interrupt. It works now, but as it gets more complex it will be a problem.
The audio callback routine should just pass the waiting audio buffer to pyAudio, and add a a task to the queue to fill the next buffer.

- Figure out sound generation strategy
Can there be recursive connections between audio modules?
I need to decide the scope of what this should be able to do. I don't want it to become so complicated that I basically reeimplement VCV Rack 
If I want that, I can just have that running and patch into it. I should look into doing that actually

- Create audio module patch interface
There needs to be a way for me to easily string together signal processing paths

- Create sequencer -> audio engine interface
This will likely end up having inputs from the global state block
There should be an object that has values that various audio modules are using as input,
and the sequencer and global state block will send outputs 
I will need to figure out how locks work in python

x Fix popping issue with audio engine
x Add VCA
- Add ADSR
For the wavetable generation, what are the bounds that I want?
attack - fom very quick to ~1 second (higher is slower)
decay - from very quick to ~0.5 second (higher is slower)
sustain - multiply by value (no negative values, [0, 1])
release - from very quick to ~4 seconds (higher is longer)
Maybe log of value for release?

Attack
from 0 -> 1 over some seconds. for now, seconds = attack input
find number of samples
total samples = sample_rate * seconds
amp = index
index += 1 / (sample rate * seconds)

Decay
from attack -> sustain
total samples = seconds * sample rate = (decay * sample rate) / 2

Release
from sustain -> 0 over up to 2 seconds


- Connect sequencer to audio engine
- Add multiple tracks/voices
- Add GUI interface to stand in for sensor devices

